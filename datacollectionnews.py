# -*- coding: utf-8 -*-
"""DataCollectionNews.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yK7clp3pCPONhkmfzQlpvaZ2VaQxcCec
"""

import requests

URL="https://edition.cnn.com/article/sitemap-2021-3.html"

page=requests.get(URL)

from bs4 import BeautifulSoup

soup = BeautifulSoup(page.content, 'html.parser')

div_containers=soup.findAll(class_='sitemap-entry')
list_container = div_containers[1]
entries = list_container.findAll('li')

dates = ["2021-03-11", "2021-03-12"]

fil_entries = []

for entry in entries:
  if entry.find(class_='date').text.strip() in dates:
    fil_entries.append(entry)

fil_entries

news_json = []

for entry in fil_entries:
  date=entry.find(class_='date').text.strip()

  url=entry.find(class_='sitemap-link').a.get("href")
  page=requests.get(url)
  soup=BeautifulSoup(page.content, 'html.parser')

  title=soup.find("h1", {"class": "pg-headline"}).text.strip()
  author=soup.find("span", {"class": "metadata__byline__author"}).text.strip()
  author=author.replace('By ', '')
  author=author.replace(', CNN', '')
  paragraphs=soup.find_all("div", {"class": "zn-body__paragraph"})
  speakable=soup.find("p", {"class": "zn-body__paragraph speakable"}).text.strip()
  article=speakable
  for i in range(len(paragraphs)):
    article = article + ' ' + paragraphs[i].text.strip()

  news_json.append({
      "date": date,
      "title": title,
      "article": article,
      "author": author,
  })

news_json

import json
with open('/content/news.json', 'w') as outfile:
    json.dump(news_json, outfile)

